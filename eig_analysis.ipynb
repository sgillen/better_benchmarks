{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sgillen/anaconda3/envs/baselines/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sgillen/work/seagul/seagul/envs/__init__.py:49: UserWarning: Warning, pybullet envs not installed\n",
      "  warnings.warn(\"Warning, pybullet envs not installed\")\n",
      "2021-05-11 19:15:52,649\tINFO services.py:1269 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer_name:  PPOFrac\n",
      "excepting /home/sgillen/work/better_benchmarks/simple_fr0/PPOFrac_2021-05-06_19-14-11/experiment_state-2021-05-06_19-14-11.json from run_dirs\n",
      "excepting /home/sgillen/work/better_benchmarks/simple_fr0/PPOFrac_2021-05-06_19-14-11/basic-variant-state-2021-05-06_19-14-11.json from run_dirs\n",
      "trainer_name:  PPOC\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import ray\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "import ray.rllib.agents.ddpg as ddpg\n",
    "import ray.rllib.agents.ddpg.td3 as td3\n",
    "import ray.rllib.agents.ars as ars\n",
    "import xarray as xr\n",
    "\n",
    "from run_rllib import PPOCTrainer, PPOFracTrainer, A2CCTrainer, A2CFracTrainer, ARSCTrainer, ARSFracTrainer\n",
    "string_2_trainer = {\"PPOC\":PPOCTrainer, \"PPOFrac\":PPOFracTrainer, \"A2CC\":A2CCTrainer, \\\n",
    "                    \"A2CFrac\":A2CFracTrainer, \"ARSC\":ARSCTrainer, \"ARSFrac\":ARSFracTrainer}\n",
    "\n",
    "import ray.rllib.agents.sac as sac\n",
    "import seagul.envs\n",
    "import numpy as np\n",
    "from numpy import pi\n",
    "import gym\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#from simple_pid import PID\n",
    "\n",
    "import dill\n",
    "import pickle5 as pickle\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from itertools import product\n",
    "from seagul.plot import smooth_bounded_curve\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from seagul.mesh import mesh_dim\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import copy\n",
    "#jup_dir = \"/home/sgillen/work/\"\n",
    "#jup_dir = \"/home/sgillen/\"\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "def do_rollout_pert(env, trainer, initial_pos, num_steps=10, deterministic=False):\n",
    "    torch.autograd.set_grad_enabled(False)\n",
    "    act_list = []\n",
    "    obs_list = []\n",
    "    rew_list = []\n",
    "\n",
    "    obs = my_reset(env, initial_pos)\n",
    "    done = False\n",
    "\n",
    "    for cur_step in range(num_steps):\n",
    "        obs_list.append(obs)\n",
    "\n",
    "        samples, _, out_dict = trainer.compute_action(obs, full_fetch=True)\n",
    "        means = out_dict['action_dist_inputs']\n",
    "        means = means[:len(means)//2]\n",
    "\n",
    "        if deterministic:\n",
    "            act = means\n",
    "        else:\n",
    "            act = samples\n",
    "        obs, rew, done, _ = env.step(act)\n",
    "        \n",
    "        act_list.append(act)\n",
    "        rew_list.append(rew)\n",
    "\n",
    "    \n",
    "    ep_obs = np.stack(obs_list)\n",
    "    ep_act = np.stack(act_list)\n",
    "    ep_rew = np.array(rew_list)\n",
    "    ep_rew = ep_rew.reshape(-1, 1)\n",
    "\n",
    "    torch.autograd.set_grad_enabled(True)\n",
    "    return ep_obs, ep_act, ep_rew\n",
    "\n",
    "\n",
    "\n",
    "def do_contact_rollout(env, trainer, ep_length, render=False, deterministic=False):\n",
    "    torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "    act_list = []\n",
    "    obs_list = []\n",
    "    rew_list = []\n",
    "    con_list = []\n",
    "\n",
    "    obs = env.reset()\n",
    "    cur_step = 0\n",
    "\n",
    "    while cur_step < ep_length:\n",
    "        obs_list.append(obs)\n",
    "        con_list.append(env.unwrapped.sim.data.ncon)\n",
    "\n",
    "        \n",
    "        samples, _, out_dict = trainer.compute_action(obs, full_fetch=True)\n",
    "        means = out_dict['action_dist_inputs']\n",
    "        means = means[:len(means)//2]\n",
    "\n",
    "        if deterministic:\n",
    "            act = means\n",
    "        else:\n",
    "            act = samples\n",
    "        \n",
    "        obs, rew, done, _ = env.step(act)\n",
    "\n",
    "        if render:\n",
    "            env.render()\n",
    "            time.sleep(.01)\n",
    "        \n",
    "        act_list.append(act)\n",
    "        rew_list.append(rew)\n",
    "\n",
    "        cur_step += 1\n",
    "\n",
    "    ep_obs = np.stack(obs_list)\n",
    "    ep_act = np.stack(act_list)\n",
    "    ep_rew = np.array(rew_list)\n",
    "    ep_rew = ep_rew.reshape(-1, 1)\n",
    "\n",
    "    \n",
    "    ep_con = np.array(con_list)\n",
    "    ep_con = ep_con.reshape(-1, 1)\n",
    "\n",
    "    torch.autograd.set_grad_enabled(True)\n",
    "    return ep_obs, ep_act, ep_rew, ep_con\n",
    "\n",
    "\n",
    "def mdim_stable(obs, act, rew):\n",
    "    m = None\n",
    "\n",
    "    if obs.shape[0] == 1000:\n",
    "        gait_start = 200\n",
    "        target_obs = obs[gait_start:]\n",
    "    else:\n",
    "        m = obs.shape[1] / 2\n",
    "\n",
    "    if m is None:\n",
    "        m, _, _, _ = mesh_dim(target_obs)\n",
    "        m = np.clip(m, .1, obs.shape[1] / 2)\n",
    "\n",
    "    return m\n",
    "\n",
    "base_dir = os.getcwd() + \"/simple_fr0/\"\n",
    "\n",
    "trainer_dict = {}\n",
    "\n",
    "        \n",
    "def get_config_and_df(checkpoint_path, plt_reward=False):\n",
    "    config_path =  '/'.join(checkpoint_path.split('/')[:-2]) + '/params.pkl'\n",
    "    config = pickle.load(open(config_path, 'rb'))\n",
    "    env_name = config['env']\n",
    "\n",
    "\n",
    "    csv_path = '/'.join(checkpoint_path.split('/')[:-2]) + '/progress.csv'\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if plt_reward:\n",
    "        plt.plot(df['episode_reward_mean'])\n",
    "        plt.figure()\n",
    "        \n",
    "    return config, df\n",
    "    \n",
    "    \n",
    "\n",
    "for trainer_dir in os.scandir(base_dir):\n",
    "    trainer_name = trainer_dir.path.split(\"/\")[-1].split(\"_\")[0]\n",
    "    print(\"trainer_name: \", trainer_name)\n",
    "    for run_dir in os.scandir(trainer_dir.path):\n",
    "        env_name = re.search(\"env=([a-zA-Z1-9\\-])+\", run_dir.path)\n",
    "        try:\n",
    "            env_name = env_name.group(0).split(\"=\")[1]\n",
    "            for run_file in os.scandir(run_dir.path):\n",
    "                if \"checkpoint_\" in run_file.path:\n",
    "                    checkpoint_path = f\"{run_file.path}/checkpoint-{run_file.path.split('_')[-1].lstrip('0')}\"\n",
    "                    #print(checkpoint_path)\n",
    "\n",
    "\n",
    "                    if trainer_name not in trainer_dict:\n",
    "                        trainer_dict[trainer_name] = {env_name:[checkpoint_path]}\n",
    "                    else:\n",
    "                        if env_name not in trainer_dict[trainer_name]:\n",
    "                            trainer_dict[trainer_name][env_name] = [checkpoint_path]\n",
    "                        else:\n",
    "                            trainer_dict[trainer_name][env_name].append(checkpoint_path)\n",
    "\n",
    "\n",
    "        except AttributeError:\n",
    "            print(f\"excepting {run_dir.path} from run_dirs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build_ext\n"
     ]
    }
   ],
   "source": [
    "trainer_name = \"PPOC\"\n",
    "seed = 0\n",
    "#===============================\n",
    "env_name = \"Walker2d-v2\"\n",
    "post_names = ['identity', 'mdim_div']\n",
    "\n",
    "def my_reset(env, point):\n",
    "    env.reset()\n",
    "    qpos = np.concatenate((np.array([0.0]), point[:8]))\n",
    "    qvel = point[8:]\n",
    "    env.unwrapped.set_state(qpos, qvel)\n",
    "    return env.unwrapped._get_obs()\n",
    "\n",
    "rollout_length = 1000\n",
    "lookback_length = 50\n",
    "\n",
    "#===============================\n",
    "# env_name = \"HalfCheetah-v2\"\n",
    "# post_names = ['identity', 'mdim_div']\n",
    "\n",
    "# def my_reset(env, point):\n",
    "#     env.reset()\n",
    "#     qpos = np.concatenate((np.array([0.0]), point[:8]))\n",
    "#     qvel = point[8:]\n",
    "#     env.unwrapped.set_state(qpos, qvel)\n",
    "#     return env.unwrapped._get_obs()\n",
    "\n",
    "# seeds = [0,1,2,3,4,5,6,7,8,9]\n",
    "# rollout_length = 100\n",
    "# lookback_length = 5\n",
    "#===============================\n",
    "# env_name = \"Hopper-v2\"\n",
    "# post_names = ['madodiv', 'mdim_div']\n",
    "\n",
    "# def my_reset(env, point):\n",
    "#     env.reset()\n",
    "#     qpos = np.concatenate((np.array([0.0]), point[:5]))\n",
    "#     qvel = point[5:]\n",
    "#     env.unwrapped.set_state(qpos, qvel)\n",
    "#     return env.unwrapped._get_obs()\n",
    "\n",
    "# seeds = [0,1,2,3,4,5,6,7,8,9]\n",
    "# rollout_length = 3\n",
    "# lookback_length = 1\n",
    "# ===============================\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make(env_name)\n",
    "n_states = env.observation_space.shape[0]\n",
    "del env\n",
    "# data = torch.load(f\"./data_mcshdim4/{env_name}.xr\")\n",
    "# policy_dict = data.policy_dict\n",
    "\n",
    "# init_data = torch.load(f\"./data17/{env_name}.xr\")\n",
    "# init_pol_dict = init_data.policy_dict\n",
    "# policy_dict['identity'] = init_pol_dict['identity']\n",
    "# policy_dict['madodiv'] = init_pol_dict['madodiv']\n",
    "\n",
    "\n",
    "\n",
    "# exp_names = [fn.__name__ for fn in data.attrs['post_fns']]\n",
    "# num_seeds = len(policy_dict[exp_names[0]])\n",
    "# mesh_sizes_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=31677)\u001b[0m WARNING:tensorflow:From /home/sgillen/anaconda3/envs/baselines/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=31677)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=31677)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=31675)\u001b[0m WARNING:tensorflow:From /home/sgillen/anaconda3/envs/baselines/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=31675)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=31675)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=31677)\u001b[0m /home/sgillen/work/seagul/seagul/envs/__init__.py:49: UserWarning: Warning, pybullet envs not installed\n",
      "\u001b[2m\u001b[36m(pid=31677)\u001b[0m   warnings.warn(\"Warning, pybullet envs not installed\")\n",
      "\u001b[2m\u001b[36m(pid=31675)\u001b[0m /home/sgillen/work/seagul/seagul/envs/__init__.py:49: UserWarning: Warning, pybullet envs not installed\n",
      "\u001b[2m\u001b[36m(pid=31675)\u001b[0m   warnings.warn(\"Warning, pybullet envs not installed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=31675)\u001b[0m running build_ext\n",
      "\u001b[2m\u001b[36m(pid=31677)\u001b[0m running build_ext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-11 19:23:35,388\tINFO trainable.py:378 -- Restored on 128.111.57.96 from checkpoint: /home/sgillen/work/better_benchmarks/simple_fr0/PPOFrac_2021-05-06_19-14-11/PPOFrac_Walker2d-v2_e98ad_00000_0_env=Walker2d-v2_2021-05-06_19-14-11/checkpoint_000302/checkpoint-302\n",
      "2021-05-11 19:23:35,390\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 302, '_timesteps_total': None, '_time_total': 49880.600227832794, '_episodes_total': 54662}\n",
      "2021-05-11 19:24:38,831\tINFO trainable.py:378 -- Restored on 128.111.57.96 from checkpoint: /home/sgillen/work/better_benchmarks/simple_fr0/PPOFrac_2021-05-06_19-14-11/PPOFrac_Walker2d-v2_e98ad_00000_0_env=Walker2d-v2_2021-05-06_19-14-11/checkpoint_000302/checkpoint-302\n",
      "2021-05-11 19:24:38,832\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 302, '_timesteps_total': None, '_time_total': 49880.600227832794, '_episodes_total': 54662}\n",
      "2021-05-11 19:25:41,597\tINFO trainable.py:378 -- Restored on 128.111.57.96 from checkpoint: /home/sgillen/work/better_benchmarks/simple_fr0/PPOFrac_2021-05-06_19-14-11/PPOFrac_Walker2d-v2_e98ad_00000_0_env=Walker2d-v2_2021-05-06_19-14-11/checkpoint_000302/checkpoint-302\n",
      "2021-05-11 19:25:41,600\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 302, '_timesteps_total': None, '_time_total': 49880.600227832794, '_episodes_total': 54662}\n",
      "2021-05-11 19:26:45,566\tINFO trainable.py:378 -- Restored on 128.111.57.96 from checkpoint: /home/sgillen/work/better_benchmarks/simple_fr0/PPOFrac_2021-05-06_19-14-11/PPOFrac_Walker2d-v2_e98ad_00000_0_env=Walker2d-v2_2021-05-06_19-14-11/checkpoint_000302/checkpoint-302\n",
      "2021-05-11 19:26:45,568\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 302, '_timesteps_total': None, '_time_total': 49880.600227832794, '_episodes_total': 54662}\n",
      "2021-05-11 19:27:49,009\tINFO trainable.py:378 -- Restored on 128.111.57.96 from checkpoint: /home/sgillen/work/better_benchmarks/simple_fr0/PPOFrac_2021-05-06_19-14-11/PPOFrac_Walker2d-v2_e98ad_00000_0_env=Walker2d-v2_2021-05-06_19-14-11/checkpoint_000302/checkpoint-302\n",
      "2021-05-11 19:27:49,010\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 302, '_timesteps_total': None, '_time_total': 49880.600227832794, '_episodes_total': 54662}\n",
      "2021-05-11 19:28:52,964\tINFO trainable.py:378 -- Restored on 128.111.57.96 from checkpoint: /home/sgillen/work/better_benchmarks/simple_fr0/PPOFrac_2021-05-06_19-14-11/PPOFrac_Walker2d-v2_e98ad_00000_0_env=Walker2d-v2_2021-05-06_19-14-11/checkpoint_000302/checkpoint-302\n",
      "2021-05-11 19:28:52,966\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 302, '_timesteps_total': None, '_time_total': 49880.600227832794, '_episodes_total': 54662}\n",
      "2021-05-11 19:29:57,732\tINFO trainable.py:378 -- Restored on 128.111.57.96 from checkpoint: /home/sgillen/work/better_benchmarks/simple_fr0/PPOFrac_2021-05-06_19-14-11/PPOFrac_Walker2d-v2_e98ad_00000_0_env=Walker2d-v2_2021-05-06_19-14-11/checkpoint_000302/checkpoint-302\n",
      "2021-05-11 19:29:57,733\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 302, '_timesteps_total': None, '_time_total': 49880.600227832794, '_episodes_total': 54662}\n",
      "2021-05-11 19:31:01,110\tINFO trainable.py:378 -- Restored on 128.111.57.96 from checkpoint: /home/sgillen/work/better_benchmarks/simple_fr0/PPOFrac_2021-05-06_19-14-11/PPOFrac_Walker2d-v2_e98ad_00000_0_env=Walker2d-v2_2021-05-06_19-14-11/checkpoint_000302/checkpoint-302\n",
      "2021-05-11 19:31:01,111\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 302, '_timesteps_total': None, '_time_total': 49880.600227832794, '_episodes_total': 54662}\n",
      "2021-05-11 19:32:05,043\tINFO trainable.py:378 -- Restored on 128.111.57.96 from checkpoint: /home/sgillen/work/better_benchmarks/simple_fr0/PPOFrac_2021-05-06_19-14-11/PPOFrac_Walker2d-v2_e98ad_00000_0_env=Walker2d-v2_2021-05-06_19-14-11/checkpoint_000302/checkpoint-302\n",
      "2021-05-11 19:32:05,046\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 302, '_timesteps_total': None, '_time_total': 49880.600227832794, '_episodes_total': 54662}\n"
     ]
    }
   ],
   "source": [
    "num_seeds = len(trainer_dict[trainer_name][env_name])\n",
    "num_runs = 10\n",
    "     \n",
    "eigs = xr.DataArray(np.zeros((2, num_seeds, num_runs, n_states), dtype=np.complex),\n",
    "                dims = (\"trainer\", \"seed\", \"run\", \"eig_vals\"),\n",
    "                coords = {\"trainer\":  list(trainer_dict.keys())})\n",
    "\n",
    "eigs2 = xr.DataArray(np.zeros((2, num_seeds, num_runs, n_states), dtype=np.complex),\n",
    "                dims = (\"trainer\", \"seed\", \"run\", \"eig_vals\"),\n",
    "                coords = {\"trainer\":  list(trainer_dict.keys())})\n",
    "\n",
    "eigs_bc = xr.DataArray(np.zeros((2, num_seeds, num_runs, n_states), dtype=np.complex),\n",
    "                dims = (\"trainer\", \"seed\", \"run\", \"eig_vals\"),\n",
    "                coords = {\"trainer\": list(trainer_dict.keys())})\n",
    "\n",
    "\n",
    "eigs_in = xr.DataArray(np.zeros((2, num_seeds, num_runs, n_states), dtype=np.complex),\n",
    "                dims = (\"trainer\", \"seed\", \"run\", \"eig_vals\"),\n",
    "                coords = {\"trainer\":  list(trainer_dict.keys())})\n",
    "\n",
    "failed = False\n",
    "for trainer_name in trainer_dict.keys():\n",
    "    trainer = None\n",
    "    for i_seed, checkpoint_path in enumerate(trainer_dict[trainer_name][env_name]):\n",
    "        print(f\"{seed}\")\n",
    "        for run in range(num_runs):\n",
    "            #post = 'identity'; seed = 1\n",
    "\n",
    "            config, df = get_config_and_df(checkpoint_path)\n",
    "\n",
    "\n",
    "            if trainer is None:\n",
    "                trainer = string_2_trainer[trainer_name](config)\n",
    "\n",
    "            config[\"reuse_actors\"] = True\n",
    "            trainer.reset_config(config)\n",
    "            trainer.restore(checkpoint_path)\n",
    "            env = trainer.env_creator({})\n",
    "\n",
    "\n",
    "            nom_obs, nom_acts, nom_rews, nom_con = do_contact_rollout(env,trainer,1000)\n",
    "\n",
    "            i_nom_obs = 500\n",
    "            while nom_con[i_nom_obs] or nom_con[i_nom_obs+1]:# or nom_con[i_nom_obs+2]:\n",
    "                i_nom_obs+=1\n",
    "                if i_nom_obs >= 998:\n",
    "                    failed = True\n",
    "                    break\n",
    "\n",
    "            if failed:\n",
    "                print(f\"post {post}, seed {seed}, run {run} failed!\")\n",
    "                eigs.loc[post][i_seed][run] = float('nan')\n",
    "                eigs_bc.loc[post][i_seed][run] = float('nan')\n",
    "                failed = False\n",
    "                continue\n",
    "\n",
    "            nominal_state = nom_obs[i_nom_obs]\n",
    "\n",
    "            #obs, acts, rews = do_rollout_pert(env, policy, nominal_state, num_steps=11)\n",
    "            #cmp_point = obs[-1]\n",
    "\n",
    "            delta = .1\n",
    "\n",
    "            initial_conditions = []\n",
    "            for i,s in enumerate(nominal_state):\n",
    "                nominal_state_p = np.copy(nominal_state)\n",
    "                nominal_state_m = np.copy(nominal_state)\n",
    "                nominal_state_p[i] += delta\n",
    "                nominal_state_m[i] -= delta\n",
    "\n",
    "                initial_conditions.append((np.copy(nominal_state_p), np.copy(nominal_state_m)))\n",
    "                #initial_conditions.append((nominal_state_p, nominal_state_m))\n",
    "\n",
    "            eig_mat = np.zeros((n_states,n_states))\n",
    "            eig_mat_bc = np.zeros((n_states,n_states))\n",
    "            eig_mat_in = np.zeros((n_states,n_states))\n",
    "\n",
    "            for i, initial_condition in enumerate(initial_conditions):\n",
    "                init_state_p , init_state_m = initial_condition\n",
    "                rollout_obs_p, rollout_acts_p, rollout_rews_p = do_rollout_pert(env,trainer, init_state_p, num_steps=rollout_length)\n",
    "                rollout_obs_m, rollout_acts_m, rollout_rews_m = do_rollout_pert(env,trainer, init_state_m, num_steps=rollout_length)\n",
    "\n",
    "                sdiff = (rollout_obs_p[-lookback_length:]-rollout_obs_m[-lookback_length:])/(2*delta)\n",
    "\n",
    "                diffs = np.abs(rollout_obs_p[-lookback_length:]-rollout_obs_m[-lookback_length:])/(2*delta)\n",
    "                i_min = np.argmin(np.linalg.norm(diffs, axis=1)) \n",
    "\n",
    "                #diffs = (init_state_p - init_state_m)*.5/(2*delta)\n",
    "                #i_min = 0 \n",
    "\n",
    "\n",
    "                from scipy.interpolate import interp1d\n",
    "                upper_bound = 1\n",
    "                lower_bound = -1\n",
    "                if i_min == 0:\n",
    "                    #print(f\"post {post}, seed {seed}, run {run} imin was zero!\")\n",
    "\n",
    "                    lower_bound = 0\n",
    "                elif i_min == lookback_length-1:\n",
    "                    #print(f\"post {post}, seed {seed}, run {run} imin was lookback_length\")\n",
    "                    upper_bound = 0\n",
    "                #else:\n",
    "                #    print(f\"post {post}, seed {seed}, run {run} had a normal value\")\n",
    "\n",
    "                try:\n",
    "                    f = interp1d(np.array([-1,0,1]), np.array([sdiff[i_min+lower_bound], sdiff[i_min], sdiff[i_min+upper_bound]]).T,  fill_value=\"extrapolate\")\n",
    "\n",
    "                    fmin = lambda x: np.linalg.norm(np.abs(f(x)))\n",
    "                    fmin_vec = np.vectorize(fmin)\n",
    "\n",
    "                    from scipy.optimize import minimize\n",
    "                    sol = minimize(fmin, 0, bounds=[(lower_bound,upper_bound)], method='L-BFGS-B', options={'eps':1e-12})\n",
    "\n",
    "\n",
    "                    eig_mat_in[:,i] = f(sol.x).squeeze()\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "\n",
    "                eig_mat_bc[:,i] = diffs[i_min]\n",
    "                eig_mat[:,i] = np.copy(diffs[-1])\n",
    "\n",
    "\n",
    "\n",
    "            w,v = np.linalg.eig(eig_mat)\n",
    "            aw = abs(w)\n",
    "            aw.sort()\n",
    "\n",
    "            eigs.loc[trainer_name][i_seed][run] = copy.copy(np.flip(aw))\n",
    "            eigs2.loc[trainer_name][i_seed][run] = copy.copy(w)\n",
    "\n",
    "\n",
    "            w,v = np.linalg.eig(eig_mat_bc) \n",
    "            aw = abs(w)\n",
    "            aw.sort()\n",
    "\n",
    "            eigs_bc.loc[trainer_name][i_seed][run] = copy.copy(np.flip(aw))\n",
    "\n",
    "\n",
    "\n",
    "            w,v = np.linalg.eig(eig_mat_in) \n",
    "            aw = abs(w)\n",
    "            aw.sort()\n",
    "\n",
    "            eigs_in.loc[trainer_name][i_seed][run] = copy.copy(np.flip(aw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs_in.mean(dim=('seed', 'run')).to_dataframe('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs_in.std(dim=('seed', 'run')).to_dataframe('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in post_names:\n",
    "    means = abs(eigs_bc).mean(dim=('seed', 'run')).loc[name]\n",
    "    stds = abs(eigs_bc).std(dim=('seed', 'run')).loc[name]\n",
    "    print(f\"{name} mean: {means}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in post_names:\n",
    "    means = abs(eigs).mean(dim=('seed', 'run')).loc[name]\n",
    "    stds = abs(eigs).std(dim=('seed', 'run')).loc[name]\n",
    "    print(f\"{name} mean: {means}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = 'mdim_div'; seed = 1\n",
    "\n",
    "if post not in mesh_sizes_dict:\n",
    "    mesh_sizes_dict[post] = {}\n",
    "\n",
    "policy = policy_dict[post][seed]\n",
    "mesh = BoxMesh(.2)\n",
    "mesh_sizes = []\n",
    "\n",
    "#init_states = np.linspace(-.3, .3, num=2)\n",
    "#init_conditions = np.meshgrid(*[init_states]*17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000000):\n",
    "    obs, acts, rews, mesh = do_rollout_mesh(env, policy, mesh)\n",
    "    mesh_sizes.append(len(mesh))\n",
    "plt.plot(mesh_sizes)\n",
    "mesh_sizes_dict[post][seed] = mesh_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mesh_sizes_dict['identity'][1])\n",
    "plt.plot(mesh_sizes_dict['mdim_div'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "env_name = \"Ant-v2\"\n",
    "post_names = ['identity', 'mdim_div']\n",
    "\n",
    "def my_reset(env, point):\n",
    "    env.reset()\n",
    "    qpos = np.concatenate((np.array([0.0, 0.0]), point[:13]))\n",
    "    qvel = point[13:27]\n",
    "    env.unwrapped.set_state(qpos, qvel)\n",
    "    return env.unwrapped._get_obs()\n",
    "\n",
    "seeds = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "rollout_length = 1000\n",
    "lookback_length = 100\n",
    "#==============================\n",
    "\n",
    "env = gym.make(env_name)\n",
    "data = torch.load(f\"./data_mcshdim4/{env_name}.xr\")\n",
    "policy_dict = data.policy_dict\n",
    "\n",
    "init_data = torch.load(f\"./data17/{env_name}.xr\")\n",
    "init_pol_dict = init_data.policy_dict\n",
    "policy_dict['identity'] = init_pol_dict['identity']\n",
    "policy_dict['madodiv'] = init_pol_dict['madodiv']\n",
    "\n",
    "\n",
    "\n",
    "exp_names = [fn.__name__ for fn in data.attrs['post_fns']]\n",
    "num_seeds = len(policy_dict[exp_names[0]])\n",
    "mesh_sizes_dict = {}\n",
    "\n",
    "rollout_length=2\n",
    "lookback_length=1\n",
    "\n",
    "# For any only\n",
    "\n",
    "num_seeds = len(seeds)\n",
    "num_runs = 10\n",
    "n_states = 27\n",
    "     \n",
    "eigs = xr.DataArray(np.zeros((2, num_seeds, num_runs, n_states), dtype=np.complex),\n",
    "                dims = (\"post\", \"seed\", \"run\", \"eig_vals\"),\n",
    "                coords = {\"post\": post_names})\n",
    "\n",
    "eigs_bc = xr.DataArray(np.zeros((2, num_seeds, num_runs, n_states), dtype=np.complex),\n",
    "                dims = (\"post\", \"seed\", \"run\", \"eig_vals\"),\n",
    "                coords = {\"post\": post_names})\n",
    "\n",
    "for post in post_names:\n",
    "    for i_seed, seed in enumerate(seeds):\n",
    "        for run in range(num_runs):\n",
    "            #post = 'identity'; seed = 1\n",
    "\n",
    "            policy = policy_dict[post][seed]\n",
    "\n",
    "            nom_obs, nom_acts, nom_rews, _ = do_long_rollout(env,policy,1000)\n",
    "\n",
    "            nominal_state = nom_obs[500]\n",
    "\n",
    "            #obs, acts, rews = do_rollout_pert(env, policy, nominal_state, num_steps=11)\n",
    "            #cmp_point = obs[-1]\n",
    "\n",
    "            delta = .1\n",
    "\n",
    "            initial_conditions = []\n",
    "            for i,s in enumerate(nominal_state[:27]):\n",
    "                nominal_state_p = np.copy(nominal_state)\n",
    "                nominal_state_m = np.copy(nominal_state)\n",
    "                nominal_state_p[i] += delta\n",
    "                nominal_state_m[i] -= delta\n",
    "\n",
    "                initial_conditions.append((nominal_state_p, nominal_state_m))\n",
    "\n",
    "\n",
    "            eig_mat = np.zeros((n_states,n_states))\n",
    "            eig_mat_bc = np.zeros((n_states,n_states))\n",
    "\n",
    "            for i, initial_condition in enumerate(initial_conditions):\n",
    "                init_state_p , init_state_m = initial_condition\n",
    "                rollout_obs_p, rollout_acts_p, rollout_rews_p = do_rollout_pert(env,policy, init_state_p, num_steps=rollout_length)\n",
    "                rollout_obs_m, rollout_acts_m, rollout_rews_m = do_rollout_pert(env,policy, init_state_m, num_steps=rollout_length)\n",
    "                \n",
    "                rollout_obs_p = rollout_obs_p[:,:27]; rollout_obs_m = rollout_obs_m[:,:27]\n",
    "                \n",
    "                diffs = np.abs(rollout_obs_p[-lookback_length:].numpy()-rollout_obs_m[-lookback_length:].numpy()) - np.abs(init_state_p[:27] - init_state_m[:27])\n",
    "                i_min = np.argmin(np.linalg.norm(diffs, axis=1)) \n",
    "                \n",
    "                eig_mat_bc[:,i] = diffs[i_min]\n",
    "                eig_mat[:,i] = diffs[-1]\n",
    "\n",
    "                \n",
    "            w,v = np.linalg.eig(eig_mat)\n",
    "            aw = abs(w)\n",
    "            aw.sort()\n",
    "            \n",
    "            eigs.loc[post][i_seed][run] = copy.copy(np.flip(aw))\n",
    "            \n",
    "            w,v = np.linalg.eig(eig_mat_bc) \n",
    "            aw = abs(w)\n",
    "            aw.sort()\n",
    "            \n",
    "            eigs_bc.loc[post][i_seed][run] = copy.copy(np.flip(aw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs_bc.std(dim=('seed', 'run')).to_dataframe('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mujoco 1.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
